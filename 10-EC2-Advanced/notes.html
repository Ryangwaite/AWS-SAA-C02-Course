<h2>Advanced EC2</h2>
<h3>Bootstrapping EC2 using User Data</h3>
<p>Bootstrapping is a process where scripts or other config steps can be run when
an instance is first launched. This allows an instance to be brough to service
in a particular configured state.</p>
<p>In systems automation, bootstrapping allows the system to self configure
or perform some self configuration steps. In AWS this is
<strong>EC2 Build Automation</strong>.</p>
<p>This could perform some software installs and post install configs.</p>
<p>Bootstrapping is done using user data - accessed via the meta-deta IP</p>
<p><a href="http://169.254.169.254/latest/user-data">http://169.254.169.254/latest/user-data</a></p>
<p>Anything you pass in is executed by the instance OS. It is excecuted
only once on launch!</p>
<p>EC2 doesn't validate the user data. You can tell EC2 to pass in trash data
and the data will be passed. The OS needs to understand the user data.</p>
<h4>Bootstrapping Architecture</h4>
<p>An AMI is used to launch an EC2 instance in the usual way to create
an EBS volume that is attached to the EC2 instance. This is based on the
block mapping inside the AMI.</p>
<p>Now the EC2 service provides some userdata through to the EC2 instance.
There is software within the OS running which is designed to look at the
metadata IP for any user data. If it sees any user data, it executes
this on launch of that instance.</p>
<p>This is treated like any other script the OS runs. At the end of running
the script, the instance will be in:</p>
<ul>
<li>Running state and ready for service</li>
<li>Bad config but still likely running
<ul>
<li>The instance will probably still pass its checks</li>
<li>It will not be configured as you excpected</li>
</ul>
</li>
</ul>
<h4>User Data Key Points</h4>
<p>EC2 doesn't know what the user data contains, it's just a block of data.</p>
<p>The user data is not secure, anyone can see what gets passed in. For this
reason it is important not to pass passwords or long term credentials.</p>
<p>User data is limited to 16 KB in size. Anything larger than this will
need to pass a script to download the larger set of data.</p>
<p>User data can be modified if you stop the instance, change the user
data, then restart the instance.</p>
<p>The contents are only excecuted once at launch.</p>
<h4>Boot-Time-To-Service-Time</h4>
<p>How quickly after you launch an instance is it ready for service. This
includes the time for EC2 to configure the instance and any software
downloads that are needed for the user.</p>
<p>When looking at an AMI, this can be measured in minutes.</p>
<p>AMI baking will front load the time needed.</p>
<p>The optimal way is to use AMI baking</p>
<h3>AWS::CloudFormation::Init</h3>
<p><strong>cfn-init</strong> is a helper script installed on EC2 OS.</p>
<p>This is a simple configuration management system.</p>
<p>Procedural (user Data) vs Desired State (cfn-init)</p>
<p>Packages, groups, users, sources, files, commands, services, and ownerships.</p>
<p>This is executed as any other command by passing into the instance with
the user-data.</p>
<p>This is provided with directives via Metadata and AWS::CloudFormation::Init on
a CFN resource</p>
<h4>cfn-init explained</h4>
<p>Starts off with a <strong>cloud formation template</strong>
This has a logical resource within it which is to create an EC2 instance.</p>
<p>This has a specific section called <code>Metadata:</code></p>
<p>This then passes in the information passed in as <code>UserData</code></p>
<p>cfn-init gets variables passed into the userdata by cloud formation</p>
<p>It knows the desired state desired by the user and can work towards a
final stated configuration</p>
<p>This can monitor the userdata and change things as the EC2 data changes.</p>
<h4>CreationPolicy and Signals</h4>
<p>The template has a specific part designated signals</p>
<p>A creation policy is added to a logical resource. It is provided a
timeout value. The resource itself will trigger a signal that cloud formation
can continue</p>
<h3>EC2 Instance Roles</h3>
<p>IAM roles are the best practice ways for services to be granted permissions.</p>
<p>Roles that an instance can assume to grant permissions for resources within.</p>
<p>Starts with an IAM role with a permissions policy.</p>
<p>EC2 instance role allows the EC2 service to assume that role.</p>
<p>The <strong>instance profile</strong> is the item that allows the permissions inside
the instance.</p>
<p>When IAM roles are assumed, you are provided temporary roles based on the
permission assigned to that role. These credentials are passed through
instance <strong>meta-data</strong>.</p>
<p>EC2 and the secure token service ensure the credentials never expire.</p>
<p>Key facts</p>
<ul>
<li>Credentials are inside meta-data</li>
<li>iam/security-credentials/role-name</li>
<li>automatically rotated - always valid</li>
<li>the resources need to check the meta-data periodically</li>
<li>should always use roles compared to storing long term credentials</li>
<li>CLI tools use role credentials automatically</li>
</ul>
<h3>AWS System Manager Parameter Store</h3>
<p>Passing secrets into an EC2 instance is bad practice because anyone
who has access to the meta-data has access to the secrets.</p>
<p>Parameter store allows for storage of <strong>configuration</strong> and <strong>secrets</strong></p>
<ul>
<li>Strings</li>
<li>StringList</li>
<li>SecureString</li>
</ul>
<p>You can store license codes, database strings, and full configs and passwords.</p>
<p>Parameter store allows for hierarchies and versioning.</p>
<p>It can store plaintext and ciphertext. This integrates with <strong>kms</strong> to
encrypt passwords.</p>
<p>Allows for public parameters such as the latest AMI parameter to be stored
and referenced for EC2 creating.</p>
<p>This is a public service so any services needs access to the public sphere or
to be an AWS service.</p>
<p>Applications, EC2 instances, lambda functions can all request access to
parameter store.</p>
<p>This is tied closely to IAM and could use long term credentials such
as access keys, or short term use of IAM roles.</p>
<p>Allows for simple or complex sets of parameters.</p>
<h3>System and Application Logging on EC2</h3>
<p>Cloudwatch monitors the outside metrics of an instance
Cloudwatch logs is for logging</p>
<p>Neither natively capture data inside an instance.</p>
<p>CloudWatch Agent is required for OS visible data. It sends this data into CW</p>
<p>For CW to function, it needs configuration and permissions in addition
to having to install the cloud watch agent.</p>
<p>The cloudwatch agent needs to know what information to inject
into cloud watch and cloud watch logs.</p>
<p>The agent needs some permissions to interact with AWS. This is done with an
IAM role as best practice. The IAM role has permissions to interact
with CW logs. The IAM role is attached to the instance which provides
the instance and anything running on the instance, permissions to manage
CW logs.</p>
<p>The data requested is then injected in CW logs.</p>
<p>There is one log group for each individual log we want to capture</p>
<p>There is one log stream for each group for each instance that needs
management.</p>
<p>We can use parameter store to store the configuration for the CW agent.</p>
<h3>EC2 Placement Groups</h3>
<h4>Cluser - Pack instances close together</h4>
<p>Achieves the highest level of performance available with EC2.</p>
<p>Best practice is to launch all of the instances within that group at the
same time.</p>
<p>If you launch with 9 instances and AWS places you in a place with capacity
for 12, you are now limited in how many you can add.</p>
<p>Cluser placements need to be part of the same AZ. The idea with cluster
placement groups are generally the same rack, but they can even be the same
EC2 host.</p>
<p>All members have direct connections to each other. They can achieve
10 Gbps single stream vs 5 Gbps normally. They also have the lowest
latency and max PPS possible in AWS.</p>
<p>If the hardware fails, the entire cluster will fail.</p>
<h5>Cluster Exams</h5>
<p>Clusters can't span AZs. The first AZ used will lock down the cluster.</p>
<p>They can span VPC peers.</p>
<p>Requires a supported instance type.</p>
<p>Best practice to use the same type of instance and launch all at once.</p>
<p>This is the only way to achieve <strong>10Gbps SINGLE stream</strong>, other data metrics
assume multiple streams.</p>
<h4>Spread - Keep instances seperated</h4>
<p>This provides the best resillience and availability.</p>
<p>Spread groups can span multiple AZs. Information will be put on distinct
racks with their own network or power supply. There is a limit of 7 instances
per AZ. The more AZs in a region, the more instances inside a spread placement
group.</p>
<h5>Spread Exams</h5>
<p>Provides the highest level of availability and resillience. Each instance
by default runs from a different rack.</p>
<p>7 instances per AZ is a hard limit.</p>
<p>Not supported for dedicated instances or hosts.</p>
<p>Use case: small number of critical instances that need to be kept seperated
from each other. Several mirrors of an application</p>
<h4>Partition - groups of instances spread apart</h4>
<p>Spread placement groups are handled by default natively by AWS.</p>
<p>If a problem occurs with one rack's networking or power, it will
at most take out one instance.</p>
<p>The main difference is you can launch as many instances in each partition
as you desire.</p>
<p>When you launch a partition group, you can allow AWS decide or you can
specifically decide.</p>
<h5>Parition Exams</h5>
<p>7 paritions maximum for each AZ</p>
<p>Instances can be placed into a specific parition, or AWS can pick.</p>
<p>This is not supported on dedicated hosts.</p>
<p>Great for HDFS, HBase, and Cassandra</p>
<h3>EC2 Dedicated Hosts</h3>
<p>EC2 host allocated to you in its entirety.</p>
<p>Pay for the host itself which is designed for a family of instances.</p>
<p>No instance charges.</p>
<p>You can pay for a host on-demand or reservation with 1 or 3 year terms.</p>
<p>The host hardware has physical sockets and cores. This dictates to how
many instances can be run.</p>
<p>Hosts are designed for a specific size and family. If you purchase one host, you
configure what type of instances you want to run on it. With the older
system you cannot mix and match. The new nitro system allows for mixing and
matching host size.</p>
<h4>Dedicated Hosts Limitations</h4>
<p>AMI Limits, some versions can't be used</p>
<p>Amazon RDS instances are not supported</p>
<p>Placement groups are not supported for dedicated hosts.</p>
<p>Hosts can be shared with other organization accounts using <strong>RAM</strong></p>
<p>This is mostly used for licensing problems related to ports.</p>
<h3>Enchanced Networking</h3>
<p>Enchanced networking uses SR-IOV - The physical network interface is aware
of the virtualization. Each instance is given exclusive access to one part
of a physical network interface card.</p>
<p>There is no charge for this and is available on most EC2 types.</p>
<p>It allows for higher IO and lower host CPU usage</p>
<p>This provides more bandwidth and higher packet per seconds.</p>
<p>In general this provides lower latency.</p>
<h4>EBS Optimized</h4>
<p>Historically network was shared, data and EBS.</p>
<p>EBS optimized there has been dedicated capacity for EBS. Most instances support
andh ave this enabled by default.</p>
<p>Some support, but enabling costs extra. This is generally enabled and comes
with standard instances.</p>
