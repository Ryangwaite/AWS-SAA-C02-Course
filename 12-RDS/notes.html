<h2>RDS</h2>
<h3>Database Refresher</h3>
<p>Systems to store and manage data.</p>
<h4>Relational (SQL)</h4>
<p>Structured Query Language (SQL) is a feature of most relational database servers
Structure in and between tables of data. There is a rigid <strong>schema</strong>. This is
defined in advance.</p>
<p>There is a fixed relationship between tables. This is defined before data
is entered into the database.</p>
<p>Every row in a table must have a value for the <strong>primary key</strong></p>
<p>There will be multiple tables, but each one needs a primary key. For every
table, there must be a value stored for every attribute in the table.</p>
<p>There is a join table with a <strong>composite key</strong>. The key must be unique in its
entirety.</p>
<p>Table relationships use keys</p>
<p>The Table Scehmas and relationships must be defined in advance.</p>
<h4>Non-Relational (NoSQL)</h4>
<p>Not a single thing, and is a catch all for everything else. There is generally
a weak or no schema.</p>
<h5>Key-Value databases</h5>
<p>The key stores the time and the Value shows the data that wants to be recorded.
So long as every key is unique, there is no real schema or structure.</p>
<p>These are really fast and highly scalable.</p>
<p>This is also used for <strong>in memory caching</strong></p>
<h5>Wide Column Store</h5>
<p>DynamoDB is one type of database.</p>
<p>Parition key - The search key<br>
Other Key - sort or range key</p>
<p>Each needs to have one key or more keys.</p>
<p>Every item in a table can also have attributes, but they don't have to be
the same between values. The only requirements is the key needs to be unique.</p>
<p>It can be <strong>single key</strong> or <strong>composite key</strong>. Either case, it must be unique.</p>
<h5>Document</h5>
<p>Documents are generally formated using JSON or XML.</p>
<p>This is an extension of a key-value store.</p>
<p>Good for orders or contacts. This is good for whole documents or deep attribute
interations.</p>
<h5>Column</h5>
<p>Row Store (MySQL) - If you needed to read the price of one item you need that
row first. If you wanted to query all of the sizes of every order, you will
need to check for each row. Often called Online Transactional Processing (OLTP).</p>
<p>Column Store (Redshift) - Columns are stored together. Bad for sales style
but good for reporting or when all values for a specific size are required.</p>
<h5>Graph</h5>
<p>Relationships between things are formally defined and stored along in the
database itself with the data. These are great for relationship driven data.</p>
<p>Nodes are objects inside a graph database. They can have properties.</p>
<p>Edges are relationships between the nodes. They have a direction.</p>
<p>Relationships can also have values associated with them and they are also
stored inside the database.</p>
<p>Relationships are fast because interactions can be queried.</p>
<h3>Databases on EC2</h3>
<p>It is always a bad idea to do this. Splitting an instance over different
AZs adds a small cost to moving the data between AZs if it happens.</p>
<h4>Reasons EC2 Database might make sense</h4>
<p>You might need access to the OS of the Database. You should question
if a client requests this, it rarely is needed.</p>
<p>Advanced DB Option tuning (DBROOT) AWS provides options against this.</p>
<p>This is typically a vendor that demands this.</p>
<p>DB or DB version that AWS doesn't provide.</p>
<p>You might need a specific version of an OS and DB that AWS doesn't provide.</p>
<h4>Reasons why you really shouldn't run a database on EC2</h4>
<p><strong>Admin overhead</strong> is intense to manage EC2 and DBHost compatible</p>
<p>Backup and Disaster Management adds complexity.</p>
<p>EC2 is running in a single AZ. If the zone fails, access to the database fails.</p>
<p>Will miss out on features from AWS DB products.</p>
<p>EC2 is ON or OFF, there is no way to scale easily.</p>
<p><strong>Replication</strong> the skills and setup time to monitor this</p>
<p>Performance will be slower than AWS options.</p>
<h3>Relational Database Service (RDS)</h3>
<p>Database-as-a-service (DBaaS) - not entirely true more of
DatabaseServer-as-a-service. Managed Database Instance for one or more databases</p>
<p>Multiple engines are MySQL, MariaDB, PostgreSQL, Oracle, Microsoft SQL</p>
<p>Amazon Aurora. This is so different from normal RDS, it is a seperate product.</p>
<h4>RDS Database Instance</h4>
<p>Runs one of a few types of database engines and can contain multiple
user created databases. Create one when you provision the instance, but
multiple can be created after.</p>
<p>Database connects with a CNAME. RDS uses standard database engines.</p>
<p>The database can be optimized for:</p>
<ul>
<li>db.m5 general</li>
<li>db.r5 memory</li>
<li>db.t3 burst</li>
</ul>
<p>There is an associated size and AZ selected.</p>
<p>When you provision an instance, you provision storage that is dedicated
to that instance. This is EBS storage located in the same AZ. RDS is vulnerable
to failures in that AZ.</p>
<p>The storage can be allocated with SSD or magnetic.</p>
<p>io1 - high IO<br>
gp2 - same burst pool<br>
magnetic - compatibility</p>
<p>Billing is per instance and hourly rate for that compute. You are billed
for storage allocated.</p>
<h3>RDS Multi AZ (High-Availability)</h3>
<p>RDS Access ONLY via database CNAME. The CNAME will point at the primary
instance. You cannot access the standby replica for any reason via RDS.</p>
<p>The standby replica cannot be used for extra capacity.</p>
<p><strong>Syncronous Replication</strong> is a keyword:</p>
<ol>
<li>Database writes happen</li>
<li>Primary database instance commits changes</li>
<li>Same time as the write is happening, standby replication is happening</li>
<li>Standby replica commits writes.</li>
</ol>
<p>If any error occurs with the primary database, AWS detects this and will
failover within 60 to 120 seconds to change to the new database.</p>
<p>This does not provide fault tolerance - there will be some impact during change</p>
<p>Exam Powerups</p>
<ul>
<li>Multi-AZ feature is not free tier, extra infrastructure for standby. Generally
two times the price.</li>
<li>The standby replica cannot be accesed directly unless a fail occurs.</li>
<li>Faillover is highly available, not fault tolerant.</li>
<li>Same region only (others AZ in the VPC).</li>
<li>Backups taken from standby (removes performance impacts).</li>
<li>AZ outage, primary failure, manual failover, instance type change, and
software patching</li>
</ul>
<h3>RDS Backup and Restores</h3>
<p>RPO - Recovery Point Objective</p>
<ul>
<li>Time between the last backup and when the failure occured</li>
<li>Amount of maximum data loss</li>
<li>Influences technical solution and cost</li>
<li>Buisness usually provides an RPO value</li>
</ul>
<p>RTO - Recovery Time Objective</p>
<ul>
<li>Time between the DR event and full recovery</li>
<li>Influenced by process, staff, tech and documentation</li>
</ul>
<p><strong>RDS Backups</strong></p>
<p>First snap is FULL size of consumed data. If you are you using single AZ</p>
<p>Manual snapshots will remain in your AWS account even after the life of
the snapshot. These need to be deleted manually.</p>
<p><strong>Automatic Snapshots</strong></p>
<p>Every 5 minutes translation logs are saved to S3. A database can then be
restored to a 5 min snapshot in time.</p>
<p>Automatic cleanups can be anywhere from 0 to 35 days. This will use
both the snapshots and the translation logs.</p>
<p>When you delete the database, they can be retained but they will expire
based on their retention period.</p>
<h4>RDS Exam Powerups</h4>
<p>When performing a restore, RDS creates a new RDS with a new endpoint address.</p>
<p>When restoring a manual snapshot, you are setting it to a single point
in time. This influences the RPO value.</p>
<p>Automated backups are different, any 5 minute point in time.</p>
<p>Backups are restored and transaction logs are replayed to bring DB to
desired point in time.</p>
<p>Restores aren't fast, think about RTO.</p>
<h3>RDS Read-Replicas</h3>
<p>Kept in sync using <strong>asyncronous replication</strong></p>
<p>It is written fully to the primary instance. Once its stored on disk, it
is then pushed to the replica. This means there could be a small lag.
These can be created in the same region or a different region. This is a
<strong>cross region replication</strong></p>
<h4>Why do these matter</h4>
<p>READ performance</p>
<ul>
<li>5 direct read-replicas per DB instance</li>
<li>Each of these provides an additional instance of read performance</li>
<li>This allows you to scale out read operations for an instance</li>
<li>Read-replicas can chain, but lag will become a problem</li>
<li>Can provide global performance improvements</li>
</ul>
<p>Availability Improvements</p>
<ul>
<li>Snapshots and backups improve RPO</li>
<li>These don't help RTOs</li>
<li>These offer near 0 RPO</li>
<li>If the primary instance fails, you can promote a read-replica to take over</li>
<li>Once it is promoted, it allows for read and write</li>
<li>Only works for failures, these can replicate data corruption, default back
to snapshots and backups</li>
<li>Promotion cannot be reversed</li>
<li>Global availability improvements provides global resilience</li>
</ul>
<h3>Amazon Aurora</h3>
<p>Aurora architecture is VERY different from RDS. At it's heart it uses a
<strong>cluster</strong></p>
<ul>
<li>A single primary instance and 0 or more replicas</li>
<li>The replicas within Aurora can be used for reads during normal operation
<ul>
<li>Provides benefits of RDS multi-AZ and read-replicas</li>
</ul>
</li>
<li>Aurora doesn't use local storage for the compute instances. An Aurora
cluster has a shared cluster volume. Provides faster provisioning.</li>
</ul>
<p>Aurora cluster functions across different availability zones.</p>
<p>There is a primary instance and a number of replicas. The read applications from
applications can use the replicas.</p>
<p>There is a shared storage of <strong>max 64 TiB, 6 Replicas, AZs</strong></p>
<p>All instances have access to all of these storage nodes. This replication
happens at the storage level. No extra resources are consumed during
replication.</p>
<p>By default the primary instance is the only one who can write. The replicas
will have read access.</p>
<p>Aurora automatically detect hardware failures on the shared storage. If there
is a failure, it immedietly repairs that area of disk. It automatically
recreates that data with no corruption.</p>
<p>With Aurora you can have up to 15 replicas and any of them
can be a failover target. The failover operation will be quicker because
it doesn't have to make any storage modifications.</p>
<p>Cluster shared volume is based on SSD storage by default so high IOPS and low
latency.</p>
<p>Aurora cluster does not specify the amount of storage needed. This is based on
what is consumed.</p>
<p>High water mark - billed for the most used. Storage which is freed up can
be re-used.</p>
<p>Replicas can be added and removed without requiring storage provisioning.</p>
<h4>Endpoints</h4>
<p>Cluster endpoint - points at the primary instance</p>
<p>Reader endpoint - will load balance over the available replicas</p>
<p>As additional replicas are used for reads, this is load balanced over
replicas.</p>
<h4>Costs</h4>
<ul>
<li>No free-tier option</li>
<li>Aurora doesn't support micro instances</li>
<li>Beyond RDS singleAZ (micro) Aurora provides best value.</li>
<li>Storage - GB-Month consumed, IO cost per request</li>
<li>100% DB size in backups are included</li>
</ul>
<h4>Aurora Restore, Clone and Backtrack</h4>
<p>Backups in Aurora work in the same way as RDS</p>
<p>Restores create a new cluster.</p>
<p>Backtrack allows for you to roll back to a previous point in time. You can roll
back in place to a point before that corruption.</p>
<p>Enabled on a per cluster basis and can adjust the window backtrack can perform.</p>
<p>Fast clones make a new database much faster than copying all the data. It
references the original storage and only write the differences between
those two. It only copies the difference and only store changes
between the source data and the clone.</p>
<h3>Aurora Serverless</h3>
<p>Provides a version of Aurora without worrying about the resources.
It uses ACU - Aurora Capacity Units</p>
<p>For a cluster, you can set a min and max ACU based on the load</p>
<p>Can go to 0 and be paused.</p>
<p>Consumption billing per-second basis</p>
<p>Same resilience as Aurora (6 copies across AZs)</p>
<p>ACUs are stateless and shared across many AWS customers and have no local
storage.</p>
<p>They have access to cluster storage in the same way.</p>
<p>There is a shared proxy fleet. When a customer interacts with the data
they are actually communicating with the proxy fleet. The proxy fleet
brokers an application with the ACU and ensures you can scale in and out
without worrying about usage.</p>
<h4>Aurora Serverless - Use Cases</h4>
<p>Infrequently used applications. You only pay for resources as you consume
them on a per second basis.</p>
<p>New applications</p>
<p>Great for variable workloads. It can scale in and out based on demand</p>
<p>It is good for applications with unpredictable workloads.</p>
<p>It can be used for development and test databases because it can scale back
when not needed.</p>
<p>Great for multi-tenant applications. If your incoming load is directly
tied to more people, that's fine.</p>
<h3>Aurora Global Database</h3>
<p>Replication from primary cluster volume to secondary replicas for read
operations.</p>
<p>Great for cross region disaster recovery and buisness continuity.</p>
<p>Global read scaling - low latency performance improvements for international
customers.</p>
<p>The application can perform read operations against the read database.</p>
<p>There is ~1s or less replication between regions. It is one way replication.</p>
<p>No additional CPU usage is needed, it happens on the storage layer.</p>
<p>Secondary regions can have 16 replicas.</p>
<p>All can be promoted to Read or Write with diasters.</p>
<p>There is currently max of 5 secondary regions.</p>
<h3>Aurora Multi-Master Writes</h3>
<p>Allows an aurora cluster to have multiple instances with multiple writers.</p>
<p>The default aurora mode is single-master.</p>
<ul>
<li>This is one R/W and zero or more read only replicas.</li>
<li>Cluster endpoint is normally used to write, read endpoint is used for load
balancing.</li>
</ul>
<p>Aurora Multi-master has no endpoint or load balancing. An application
can connect with one or both of the instances inside a multi-master
cluster.</p>
<p>When one of the R/W nodes, it proposes all data be commited to all storage
of the clusters. They each confirm or deny if this change is allowed.</p>
<p>The writing instance is looking for a bunch of nodes to agree. If the group
rejects it, it cancels the write in error. If it commits, it will replicate
on all storage nodes.</p>
<p>In a Multi-master cluster, it will then copy into other masters.</p>
<p>This ensures storage is updated on in-memory cache's</p>
<p>If a writer goes down in a multi-master cluster, the application will shift
all future load over to the new writter with little to no downtime.</p>
<h3>Database Migration Service (DMS)</h3>
<p>A managed database migration service. This runs using a replication instance.</p>
<p>Need to define the source and destination endpoints. These point at the
physical source and target databases.</p>
<p>One endpoint MUST be on AWS.</p>
