<h2>09-Containers</h2>
<h3>Intro to Containers</h3>
<p>Virtualisation Problems</p>
<p>AWS EC2 Host : base
AWS Hypervisor (Nitro)</p>
<p>If you run a virtual machine with 4 GB ram and 40 GB disk,
the OS can comsume 60-70% of the disk and little available
memory.</p>
<p>If all of the OS use the same or similar resources, they are
duplicates. Every restart must manipulate the entire OS.</p>
<p>What you want to do is run applications in their own
isolated enviroments for their applications to run.</p>
<p>Containers have isolated OS from each other.</p>
<h4>Image Anatomy</h4>
<p>Container is a running image of docker image.</p>
<p>These are stacks of layers and not a monolithic disk image.</p>
<p>Each line of a docker image creates a new filesystem layer.</p>
<p>Images are created from scratch or a base image.</p>
<p>Images contain read only layers, images are layer onto images.</p>
<p>Docker container is the same as a docker image, except it
has an additional READ/WRITE layer of the container.</p>
<p>If you have lots of containers with very similar base
structures, they will share the parts that overlap.</p>
<p>The other layers are reused between containers.</p>
<h4>Container Registry</h4>
<p>Registry or hub of container images.</p>
<p>Dockerfile can create a container image where it gets stored
in the container registry.</p>
<p>Docker hosts can run many containers between one or more images.</p>
<h4>Container Key Concepts</h4>
<p>Dockerfiles are used to build images</p>
<p>Portable and always run as expected. Anywhere there is a compatable host,
it will run exactly as you intended.</p>
<p>Containers are super lightweight, use the host OS for the
heavy lifting, but otherwise are light. File system layers
are shared when possible.</p>
<p>Containers only run the application and enviroment it needs.</p>
<p>Ports need to be <strong>exposed</strong> to allow outside access from
the host and beyond.</p>
<p>Application stacks can be multi container</p>
<h3>Elastic Container Service (ECS) Concepts</h3>
<p>Accepts containers and instructions you provide.</p>
<p>ECS allows you to create a cluster. Clusters are where containers run from.</p>
<p>Container images will be located on a registry.
AWS provides ECR (elastic container registry).</p>
<p>Container definition tells ECS where the container image is.</p>
<p>Task definition represents the application as a whole and stores whatever
information is needed to run the application.</p>
<p>Container is just a pointer to where the container is stored and what port is
exposed. The rest is defined at the task definition.</p>
<p>Task definitions store the resources and networking used by the task. It stores
the compatability of how the container runs. It also stores <strong>task role</strong>, an
IAM role that allows the task complete its task. This is the best practice
way to give containers the access needed for other AWS resources.</p>
<p>A lot of tasks will only have one container definition, but a task could
include one or more containers.</p>
<p>Task is not by itself highly available.</p>
<p>ECS service - Service Definition. This defines how many copies of the task
is allowed to run to load balance. You can use a service to provide scalability
and high availability.</p>
<p>Tasks or services get deployed to an ECS cluster.</p>
<p><strong>Container definition</strong> the image and the ports that will be used.</p>
<p><strong>Task definition</strong> the task role and security is defined. This is an IAM
role that is assumed. The temporary credentials allow access to AWS products
and services.</p>
<p><strong>Task role</strong> IAM role which the task assumes.</p>
<p><strong>Service</strong> how many copies of a task you want to run for scaling and
high availability.</p>
<h3>ECS Cluster Types</h3>
<p>ECS Cluster manages</p>
<ul>
<li>Scheduling and Orchestration</li>
<li>Cluster manager</li>
<li>Placement engine</li>
</ul>
<h4>EC2 mode</h4>
<p>ECS cluster is created within a VPC. It benefits from the multiple AZs that
are within that VPC.</p>
<p>You specify an initial size which will drive an <strong>auto scaling group</strong></p>
<p>ECS using EC2 mode is not a serverless solution, you need to worry about
capacity for your cluster.</p>
<p>The container instances are not delivered as a managed service, they
are managed as normal EC2 instances.</p>
<p>This is good because you can use spot pricing or prepaid EC2 servers.</p>
<h4>Fargate mode</h4>
<p>Removes more of the management overhead from ECS, no need to manage EC2.</p>
<p>There is a <strong>fargate shared infrastructure</strong> which allows all customers
to access from the same pool of resources.</p>
<p>Fargate deployment still uses a cluster with a VPC where AZs are specified.</p>
<p>For ECS tasks, they are injected into the VPC. Each task is given an
elastic network interface which has an IP address within the VPC. They then
run like an VPC resource.</p>
<p>You only pay for the container resources you use.</p>
<h4>EC2 vs ECS(EC2) vs Fargate</h4>
<p>If you already are using containers, use <strong>ECS</strong></p>
<p><strong>EC2 mode</strong> is good for a large workload with price conscious. This allows for
spot pricing and prepayment.</p>
<p>Large workload but overhead conscious <strong>Fargate</strong></p>
<p>Small or burst style workloads <strong>Fargate</strong> makes sense</p>
<p>Batch or periodic workloads <strong>Fargate</strong></p>
